import logging
import time
import sys
import os
from tqdm import tqdm
import numpy as np
import warnings
import shutil
import json
import torch
import torch.nn as nn
from pathlib import Path

from models.TGAT import TGAT
from models.MemoryModel import MemoryModel, compute_src_dst_node_time_shifts
from models.CAWN import CAWN
from models.TCL import TCL
from models.GraphMixer import GraphMixer
from models.DyGFormer import DyGFormer
from models.PopGroup import PopGroup
from models.modules import MergeLayer, PopularityPredictor
from utils.utils import set_random_seed, convert_to_gpu, get_parameter_sizes, create_optimizer
from utils.utils import get_neighbor_sampler
from evaluate_models_utils import evaluate_model_popularity_prediction
from utils.metrics import get_popularity_prediction_metrics
from utils.DataLoader import get_idx_data_loader, get_popularity_prediction_data
from utils.EarlyStopping import EarlyStopping
from utils.load_configs import get_popularity_prediction_args
from utils.visualize import visualize_fluxons

def print_requires_grad(model: nn.Module):
    for name, p in model.named_parameters():
        print(f"{name:<50} requires_grad={p.requires_grad}")

def print_grad_after_backward(model: nn.Module):
    for name, p in model.named_parameters():
        got_grad = (p.grad is not None)
        norm = p.grad.norm().item() if got_grad else None
        print(f"{name:<50} got_grad={got_grad}  grad_norm={norm}")


if __name__ == "__main__":
    torch.autograd.set_detect_anomaly(True)

    warnings.filterwarnings('ignore')

    # get arguments
    args = get_popularity_prediction_args()

    # get data for training, validation and testing

    node_raw_features, edge_raw_features, full_data, train_data, val_data, test_data = \
        get_popularity_prediction_data(dataset_name=args.dataset_name, val_ratio=args.val_ratio,
                                       test_ratio=args.test_ratio, time_interval=args.dataset_time_gap)

    # initialize validation and test neighbor sampler to retrieve temporal graph
    full_neighbor_sampler = get_neighbor_sampler(data=full_data, sample_neighbor_strategy=args.sample_neighbor_strategy,
                                                 time_scaling_factor=args.time_scaling_factor, seed=1)

    # get data loaders
    train_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(train_data.dst_node_ids))),
                                                batch_size=args.batch_size, shuffle=False)
    val_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(val_data.dst_node_ids))),
                                              batch_size=args.batch_size, shuffle=False)
    test_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(test_data.dst_node_ids))),
                                               batch_size=args.batch_size, shuffle=False)

    val_metric_all_runs, test_metric_all_runs = [], []

    for run in range(args.num_runs):
        set_random_seed(seed=run)
        global_step = 0

        args.seed = run
        # args.load_model_name = f'{args.model_name}_seed{args.seed}'
        args.save_model_name = f'popularity_prediction_{args.model_name}_seed{args.seed}'

        # set up logger
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger()
        logger.setLevel(logging.DEBUG)
        os.makedirs(f"./logs/{args.model_name}/{args.dataset_name}/{args.save_model_name}/", exist_ok=True)
        # create file handler that logs debug and higher level messages
        fh = logging.FileHandler(
            f"./logs/{args.model_name}/{args.dataset_name}/{args.save_model_name}/{args.exp}.log")
        fh.setLevel(logging.DEBUG)
        # create console handler with a higher log level
        ch = logging.StreamHandler()
        ch.setLevel(logging.WARNING)
        # create formatter and add it to the handlers
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)
        # add the handlers to logger
        logger.addHandler(fh)
        logger.addHandler(ch)

        run_start_time = time.time()
        logger.info(f"********** Run {run + 1} starts. **********")

        logger.info(f'configuration is {args}')

        # create model
        if args.model_name == 'TGAT':
            dynamic_backbone = TGAT(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                    neighbor_sampler=full_neighbor_sampler,
                                    time_feat_dim=args.time_feat_dim, num_layers=args.num_layers,
                                    num_heads=args.num_heads, dropout=args.dropout, device=args.device)
        elif args.model_name in ['JODIE', 'DyRep', 'TGN', 'TGN-id']:
            # four floats that represent the mean and standard deviation of source and destination node time shifts in the training data, which is used for JODIE
            src_node_mean_time_shift, src_node_std_time_shift, dst_node_mean_time_shift_dst, dst_node_std_time_shift = \
                compute_src_dst_node_time_shifts(train_data.src_node_ids, train_data.dst_node_ids,
                                                 train_data.node_interact_times)
            dynamic_backbone = MemoryModel(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                           neighbor_sampler=full_neighbor_sampler,
                                           time_feat_dim=args.time_feat_dim, model_name=args.model_name,
                                           num_layers=args.num_layers, num_heads=args.num_heads,
                                           dropout=args.dropout, src_node_mean_time_shift=src_node_mean_time_shift,
                                           src_node_std_time_shift=src_node_std_time_shift,
                                           dst_node_mean_time_shift_dst=dst_node_mean_time_shift_dst,
                                           dst_node_std_time_shift=dst_node_std_time_shift, device=args.device)
        elif args.model_name in ['Fluxion']:
            dynamic_backbone = PopGroup(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                        time_feat_dim=args.time_feat_dim, model_name=args.model_name,
                                        num_layers=args.num_layers, num_heads=args.num_heads,
                                        dropout=args.dropout, device=args.device,
                                        item_nums=full_data.num_unique_item_nodes,
                                        user_nums=full_data.num_unique_user_nodes,
                                        mode=args.router_mode,
                                        k_select=args.fluxion_select_num,
                                        tau_start=args.t_start,
                                        tau_end=args.t_end,
                                        total_steps=args.t_steps,
                                        fluxion_size=args.fluxion_member_num,
                                        fluxion_init_type=args.fluxion_init_type,
                                        distance_type=args.distance_type,
                                        fluxion_ema=args.ema)
        elif args.model_name == 'CAWN':
            dynamic_backbone = CAWN(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                    neighbor_sampler=full_neighbor_sampler,
                                    time_feat_dim=args.time_feat_dim, position_feat_dim=args.position_feat_dim,
                                    walk_length=args.walk_length,
                                    num_walk_heads=args.num_walk_heads, dropout=args.dropout, device=args.device)
        elif args.model_name == 'TCL':
            dynamic_backbone = TCL(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                   neighbor_sampler=full_neighbor_sampler,
                                   time_feat_dim=args.time_feat_dim, num_layers=args.num_layers,
                                   num_heads=args.num_heads,
                                   num_depths=args.num_neighbors + 1, dropout=args.dropout, device=args.device)
        elif args.model_name == 'GraphMixer':
            dynamic_backbone = GraphMixer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                          neighbor_sampler=full_neighbor_sampler,
                                          time_feat_dim=args.time_feat_dim, num_tokens=args.num_neighbors,
                                          num_layers=args.num_layers, dropout=args.dropout, device=args.device)
        elif args.model_name == 'DyGFormer':
            dynamic_backbone = DyGFormer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features,
                                         neighbor_sampler=full_neighbor_sampler,
                                         time_feat_dim=args.time_feat_dim,
                                         channel_embedding_dim=args.channel_embedding_dim, patch_size=args.patch_size,
                                         num_layers=args.num_layers, num_heads=args.num_heads, dropout=args.dropout,
                                         max_input_sequence_length=args.max_input_sequence_length, device=args.device)
        else:
            raise ValueError(f"Wrong value for model_name {args.model_name}!")
        # link_predictor = MergeLayer(input_dim1=node_raw_features.shape[1], input_dim2=node_raw_features.shape[1],
        #                             hidden_dim=node_raw_features.shape[1], output_dim=1)
        # model = nn.Sequential(dynamic_backbone, link_predictor)
        #
        # # load the saved model in the link prediction task
        # load_model_folder = f"./saved_models/{args.model_name}/{args.dataset_name}/{args.load_model_name}"
        # early_stopping = EarlyStopping(patience=0, save_model_folder=load_model_folder,
        #                                save_model_name=args.load_model_name, logger=logger, model_name=args.model_name)
        # early_stopping.load_checkpoint(model, map_location='cpu')

        # create the model for the popularity prediction task
        if args.model_name in ['Fluxion']:
            popularity_predictor = PopularityPredictor(input_dim=node_raw_features.shape[1]*4, dropout=args.dropout)
        else:
            popularity_predictor = PopularityPredictor(input_dim=node_raw_features.shape[1], dropout=args.dropout)

        model = nn.Sequential(dynamic_backbone, popularity_predictor)
        logger.info(f'model -> {model}')
        print_requires_grad(model)
        logger.info(f'model name: {args.model_name}, #parameters: {get_parameter_sizes(model) * 4} B, '
                    f'{get_parameter_sizes(model) * 4 / 1024} KB, {get_parameter_sizes(model) * 4 / 1024 / 1024} MB.')

        # follow previous work, we freeze the dynamic_backbone and only optimize the node_classifier
        optimizer = create_optimizer(model=model, optimizer_name=args.optimizer, learning_rate=args.learning_rate,
                                     weight_decay=args.weight_decay)
        model = convert_to_gpu(model, device=args.device)
        # put the node raw messages of memory-based models on device
        # if args.model_name in ['JODIE', 'DyRep', 'TGN']:
        #     for node_id, node_raw_messages in model[0].memory_bank.node_raw_messages.items():
        #         new_node_raw_messages = []
        #         for node_raw_message in node_raw_messages:
        #             new_node_raw_messages.append((node_raw_message[0].to(args.device), node_raw_message[1]))
        #         model[0].memory_bank.node_raw_messages[node_id] = new_node_raw_messages

        # save_model_folder = f"./saved_models/{args.model_name}_{args.exp}/{args.dataset_name}/{args.save_model_name}/"
        save_model_folder = f"/root/autodl-fs/KDD2026/saved_models/{args.model_name}_{args.exp}/{args.dataset_name}/{args.save_model_name}/"
        shutil.rmtree(save_model_folder, ignore_errors=True)
        os.makedirs(save_model_folder, exist_ok=True)

        early_stopping = EarlyStopping(patience=args.patience, save_model_folder=save_model_folder,
                                       save_model_name=args.save_model_name, logger=logger, model_name=args.model_name)

        loss_func = nn.MSELoss()

        for epoch in range(args.num_epochs):
            time_epoch_start = time.time()
            model.train()
            if args.model_name in ['DyRep', 'TGAT', 'TGN', 'CAWN', 'TCL', 'GraphMixer', 'DyGFormer']:
                # training process, set the neighbor sampler
                model[0].set_neighbor_sampler(full_neighbor_sampler)
            if args.model_name in ['JODIE', 'DyRep', 'TGN', 'TGN-id']:
                # reinitialize memory of memory-based models at the start of each epoch
                model[0].memory_bank.__init_memory_bank__()
            if args.model_name in ['Fluxion']:
                model[0].memory_bank.__init_memory_bank__()
                # model[0].slow_memory_bank.data.zero_()
                model[0].fluxon_bank.__init_memory_bank__()
                model[0].reset_item_history()

            # store train losses, trues and predicts
            valid_batch_num = 0
            train_total_loss, train_y_trues, train_y_predicts = 0.0, [], []
            train_idx_data_loader_tqdm = tqdm(train_idx_data_loader, ncols=120, disable=True)
            for batch_idx, train_data_indices in enumerate(train_idx_data_loader_tqdm):
                # if batch_idx == 50:
                #     break
                # if args.model_name in ['Fluxion']:
                #     if batch_idx % 500 == 0:
                #         states = model[0].fluxon_bank.get_all_fluxon().detach().clone()
                #         Path(f"./visualization/exp{args.exp}/run{run}").mkdir(parents=True, exist_ok=True)
                #         base_v = f'./visualization/fluxon_basis_D128_seed42.pt'
                #         image_path = f'./visualization/exp{args.exp}/run{run}/train_epoch{epoch}_batch{batch_idx}.jpg'
                #         visualize_fluxons(
                #             states,
                #             save_path=image_path,
                #             seed=42,
                #             basis_file=base_v,  # 相同路径 -> 相同基
                #             normalize=False,
                #             color_by="row",
                #             title=f'{batch_idx}'
                #         )
                train_data_indices = train_data_indices.numpy()
                batch_src_node_ids, batch_dst_node_ids, batch_node_interact_times, batch_edge_ids, batch_labels = \
                    train_data.src_node_ids[train_data_indices], train_data.dst_node_ids[train_data_indices], \
                        train_data.node_interact_times[train_data_indices], \
                        train_data.edge_ids[train_data_indices], train_data.labels[train_data_indices]
                if args.model_name in ['Fluxion']:
                    batch_slow_feature = train_data.slow_features[train_data_indices]
                    batch_sp_feature = train_data.sp_features[train_data_indices]
                    batch_time_feature = train_data.timeinterval_features[train_data_indices]
                # print(f'train batch: {batch_idx}')
                valid_index = np.where(batch_labels > 0)
                if sum(batch_labels) == 0:
                    # print('no loss this batch')
                    train_idx_data_loader_tqdm.set_description(
                        f'Epoch: {epoch + 1}, train for the {batch_idx + 1}-th batch, train loss: no loss')
                else:
                    valid_batch_num = valid_batch_num + 1
                if args.model_name in ['TGAT', 'CAWN', 'TCL']:
                    # get temporal embedding of source and destination nodes
                    # two Tensors, with shape (batch_size, node_feat_dim)
                    _, batch_dst_node_embeddings = \
                        model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,
                                                                          dst_node_ids=batch_dst_node_ids,
                                                                          node_interact_times=batch_node_interact_times,
                                                                          num_neighbors=args.num_neighbors)
                elif args.model_name in ['JODIE', 'DyRep', 'TGN', 'TGN-id']:
                    # get temporal embedding of source and destination nodes
                    # two Tensors, with shape (batch_size, node_feat_dim)
                    _, batch_dst_node_embeddings = \
                        model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,
                                                                          dst_node_ids=batch_dst_node_ids,
                                                                          node_interact_times=batch_node_interact_times,
                                                                          edge_ids=batch_edge_ids,
                                                                          edges_are_positive=True,
                                                                          num_neighbors=args.num_neighbors)
                elif args.model_name in ['GraphMixer']:
                    # get temporal embedding of source and destination nodes
                    # two Tensors, with shape (batch_size, node_feat_dim)
                    _, batch_dst_node_embeddings = \
                        model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,
                                                                          dst_node_ids=batch_dst_node_ids,
                                                                          node_interact_times=batch_node_interact_times,
                                                                          num_neighbors=args.num_neighbors,
                                                                          time_gap=args.time_gap)
                elif args.model_name in ['DyGFormer']:
                    # get temporal embedding of source and destination nodes
                    # two Tensors, with shape (batch_size, node_feat_dim)
                    _, batch_dst_node_embeddings = \
                        model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,
                                                                          dst_node_ids=batch_dst_node_ids,
                                                                          node_interact_times=batch_node_interact_times)
                elif args.model_name in ['Fluxion']:
                    batch_dst_node_embeddings = model[0].compute_dst_node_temporal_embeddings(
                        src_node_ids=batch_src_node_ids,
                        dst_node_ids=batch_dst_node_ids,
                        node_interact_times=batch_node_interact_times,
                        edge_ids=batch_edge_ids,
                        dst_slow_feature=batch_slow_feature,
                        valid_index=valid_index,
                        dst_sp_feature=batch_sp_feature,
                        dst_time_feature=batch_time_feature
                    )
                else:
                    raise ValueError(f"Wrong value for model_name {args.model_name}!")
                # get predicted probabilities, shape (batch_size, )
                if sum(batch_labels) != 0:
                    if args.model_name in ['Fluxion']:
                        predicts = model[1](x=batch_dst_node_embeddings).squeeze(dim=-1)
                    else:
                        predicts = model[1](x=batch_dst_node_embeddings[valid_index]).squeeze(dim=-1)
                    labels = torch.from_numpy(batch_labels[valid_index]).float().to(predicts.device)
                    labels = torch.log2(labels)
                    # print(f'labels:{labels}')
                    # print(f'predts:{predicts}')
                    # print(labels.shape)
                    # print(predicts.shape)
                    # print(labels)
                    # exit()

                    loss = loss_func(input=predicts, target=labels)
                    # print(loss)

                    train_total_loss += loss.item()

                    train_y_trues.append(labels)
                    train_y_predicts.append(predicts)

                    optimizer.zero_grad()
                    loss.backward()

                    if global_step == 10:
                        no_grad_names = [n for n, p in model.named_parameters()
                                         if p.requires_grad and p.grad is None
                                         and 'bank' not in n]
                        if args.model_name == 'TGN-id':
                            no_grad_names = [n for n, p in model.named_parameters()
                                             if p.requires_grad and p.grad is None
                                             and 'bank' not in n
                                             and 'time' not in n]
                        assert not no_grad_names, f"No grad for: {no_grad_names}"
                    global_step += 1
                    optimizer.step()
                    train_idx_data_loader_tqdm.set_description(
                        f'Epoch: {epoch + 1}, train for the {batch_idx + 1}-th batch, train loss: {loss.item()}')

                if args.model_name in ['JODIE', 'DyRep', 'TGN', 'TGN-id']:
                    # detach the memories and raw messages of nodes in the memory bank after each batch, so we don't back propagate to the start of time
                    model[0].memory_bank.detach_memory_bank()
                elif args.model_name in ['Fluxion']:
                    model[0].memory_bank.detach_memory_bank()
                    # model[0].slow_memory_bank.detach_()
                    model[0].fluxon_bank.detach_memory_bank()

            train_total_loss /= valid_batch_num
            train_y_trues = torch.cat(train_y_trues, dim=0)
            train_y_predicts = torch.cat(train_y_predicts, dim=0)

            train_metrics = get_popularity_prediction_metrics(predicts=train_y_predicts, labels=train_y_trues)

            val_total_loss, val_metrics = evaluate_model_popularity_prediction(model_name=args.model_name,
                                                                               model=model,
                                                                               neighbor_sampler=full_neighbor_sampler,
                                                                               evaluate_idx_data_loader=val_idx_data_loader,
                                                                               evaluate_data=val_data,
                                                                               loss_func=loss_func,
                                                                               num_neighbors=args.num_neighbors,
                                                                               time_gap=args.time_gap,
                                                                               infer='val',
                                                                               epoch=epoch,
                                                                               exp=args.exp)

            logger.info(
                f'Epoch: {epoch + 1}, learning rate: {optimizer.param_groups[0]["lr"]}, train loss MSLE: {train_total_loss:.4f}')
            for metric_name in train_metrics.keys():
                logger.info(f'train {metric_name}, {train_metrics[metric_name]:.4f}')
            logger.info(f'validate loss: {val_total_loss:.4f}')
            for metric_name in val_metrics.keys():
                logger.info(f'validate {metric_name}, {val_metrics[metric_name]:.4f}')
            time_epoch_end = time.time()
            print(f'epoch {epoch+1} training time is {time_epoch_end-time_epoch_start}')

            # perform testing once after test_interval_epochs
            if (epoch + 1) % args.test_interval_epochs == 0:
                if args.model_name in ['JODIE', 'DyRep', 'TGN', 'TGN-id']:
                    # backup memory bank after validating so it can be used for testing nodes (since test edges are strictly later in time than validation edges)
                    val_backup_memory_bank = model[0].memory_bank.backup_memory_bank()
                if args.model_name in ['Fluxion']:
                    val_backup_memory_bank = model[0].memory_bank.backup_memory_bank()
                    # val_backup_slow_memory_bank = model[0].slow_memory_bank.data.clone()
                    val_backup_fluxon_bank = model[0].fluxon_bank.backup_memory_bank()

                test_total_loss, test_metrics = evaluate_model_popularity_prediction(model_name=args.model_name,
                                                                                     model=model,
                                                                                     neighbor_sampler=full_neighbor_sampler,
                                                                                     evaluate_idx_data_loader=test_idx_data_loader,
                                                                                     evaluate_data=test_data,
                                                                                     loss_func=loss_func,
                                                                                     num_neighbors=args.num_neighbors,
                                                                                     time_gap=args.time_gap,
                                                                                     infer='test',
                                                                                     epoch=epoch,
                                                                                     exp=args.exp)

                if args.model_name in ['JODIE', 'DyRep', 'TGN', 'TGN-id']:
                    # reload validation memory bank for saving models
                    # note that since model treats memory as parameters, we need to reload the memory to val_backup_memory_bank for saving models
                    model[0].memory_bank.reload_memory_bank(val_backup_memory_bank)
                if args.model_name in ['Fluxion']:
                    model[0].memory_bank.reload_memory_bank(val_backup_memory_bank)
                    # model[0].slow_memory_bank.data = val_backup_slow_memory_bank.clone()
                    model[0].fluxon_bank.reload_memory_bank(val_backup_fluxon_bank)

                logger.info(f'test loss: {test_total_loss:.4f}')
                for metric_name in test_metrics.keys():
                    logger.info(f'test {metric_name}, {test_metrics[metric_name]:.4f}')

            # select the best model based on all the validate metrics
            val_metric_indicator = []
            for metric_name in val_metrics.keys():
                higher_better = False
                # if metric_name == 'pcc':
                #     higher_better = True
                if metric_name == 'rmsle':
                    val_metric_indicator.append((metric_name, val_metrics[metric_name], higher_better))
            early_stop = early_stopping.step(val_metric_indicator, model, epochs=str(epoch))

            if early_stop:
                break

        # load the best model
        early_stopping.load_checkpoint(model)

        # evaluate the best model
        logger.info(f'get final performance on dataset {args.dataset_name}...')

        # the saved best model of memory-based models cannot perform validation since the stored memory has been updated by validation data
        if args.model_name not in ['JODIE', 'DyRep', 'TGN', 'TGN-id', 'Fluxion']:
            val_total_loss, val_metrics = evaluate_model_popularity_prediction(model_name=args.model_name,
                                                                               model=model,
                                                                               neighbor_sampler=full_neighbor_sampler,
                                                                               evaluate_idx_data_loader=val_idx_data_loader,
                                                                               evaluate_data=val_data,
                                                                               loss_func=loss_func,
                                                                               num_neighbors=args.num_neighbors,
                                                                               time_gap=args.time_gap,
                                                                               infer='val',
                                                                               epoch=999,
                                                                               exp=args.exp)

        test_total_loss, test_metrics = evaluate_model_popularity_prediction(model_name=args.model_name,
                                                                             model=model,
                                                                             neighbor_sampler=full_neighbor_sampler,
                                                                             evaluate_idx_data_loader=test_idx_data_loader,
                                                                             evaluate_data=test_data,
                                                                             loss_func=loss_func,
                                                                             num_neighbors=args.num_neighbors,
                                                                             time_gap=args.time_gap,
                                                                             infer='test',
                                                                             epoch=999,
                                                                             exp=args.exp)

        # store the evaluation metrics at the current run
        val_metric_dict, test_metric_dict = {}, {}

        if args.model_name not in ['JODIE', 'DyRep', 'TGN', 'TGN-id', 'Fluxion']:
            logger.info(f'validate loss: {val_total_loss:.4f}')
            for metric_name in val_metrics.keys():
                val_metric = val_metrics[metric_name]
                logger.info(f'validate {metric_name}, {val_metric:.4f}')
                val_metric_dict[metric_name] = val_metric

        logger.info(f'test loss: {test_total_loss:.4f}')
        for metric_name in test_metrics.keys():
            test_metric = test_metrics[metric_name]
            logger.info(f'test {metric_name}, {test_metric:.4f}')
            test_metric_dict[metric_name] = test_metric

        single_run_time = time.time() - run_start_time
        logger.info(f'Run {run + 1} cost {single_run_time:.2f} seconds.')

        if args.model_name not in ['JODIE', 'DyRep', 'TGN', 'TGN-id', 'Fluxion']:
            val_metric_all_runs.append(val_metric_dict)
        test_metric_all_runs.append(test_metric_dict)

        # avoid the overlap of logs
        if run < args.num_runs - 1:
            logger.removeHandler(fh)
            logger.removeHandler(ch)

        # save model result
        if args.model_name not in ['JODIE', 'DyRep', 'TGN', 'TGN-id', 'Fluxion']:
            result_json = {
                "validate metrics": {metric_name: f'{val_metric_dict[metric_name]:.4f}' for metric_name in
                                     val_metric_dict},
                "test metrics": {metric_name: f'{test_metric_dict[metric_name]:.4f}' for metric_name in
                                 test_metric_dict}
            }
        else:
            result_json = {
                "test metrics": {metric_name: f'{test_metric_dict[metric_name]:.4f}' for metric_name in
                                 test_metric_dict}
            }
        result_json = json.dumps(result_json, indent=4)

        save_result_folder = f"./saved_results/{args.model_name}/{args.dataset_name}"
        os.makedirs(save_result_folder, exist_ok=True)
        save_result_path = os.path.join(save_result_folder, f"{args.save_model_name}.json")

        with open(save_result_path, 'w') as file:
            file.write(result_json)

    # store the average metrics at the log of the last run
    logger.info(f'metrics over {args.num_runs} runs:')

    if args.model_name not in ['JODIE', 'DyRep', 'TGN', 'TGN-id', 'Fluxion']:
        for metric_name in val_metric_all_runs[0].keys():
            logger.info(
                f'validate {metric_name}, {[val_metric_single_run[metric_name] for val_metric_single_run in val_metric_all_runs]}')
            logger.info(
                f'average validate {metric_name}, {np.mean([val_metric_single_run[metric_name] for val_metric_single_run in val_metric_all_runs]):.4f} '
                f'± {np.std([val_metric_single_run[metric_name] for val_metric_single_run in val_metric_all_runs], ddof=1):.4f}')

    for metric_name in test_metric_all_runs[0].keys():
        logger.info(
            f'test {metric_name}, {[test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs]}')
        logger.info(
            f'average test {metric_name}, {np.mean([test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs]):.4f} '
            f'± {np.std([test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs], ddof=1):.4f}')

    sys.exit()
